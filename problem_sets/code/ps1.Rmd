---
title: "PS1 - Econometrics  I"
author: "Gustavo Henrique and Bruno Tonholo"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem Set 1
### Question 1
```{r}
# Setting objects
c = matrix(c(12547, 4818, 3440, 8583, 6657, 4990, 14493, 7990, 6139, 7043, 3758, 1487, 13238, 11033, 4921),
           nrow = 5,
           ncol = 3, 
           byrow = TRUE)
p = c(1.05, 1.04, 1.1)
r = c(1.1, 1.09, 1.14)
alpha = 0.18

# Estimating beta using MME
beta_1 = c()
for (i in 1:nrow(c)) {
  c_1 = c[i, 1]
  c_2 = c[i, 2]
  p_1 = p[1]
  r_2 = r[2]
  beta_1[i] = (p_1*c_1^(-alpha))/(r_2*c_2^(-alpha))
}
beta_hat_1 = sum(beta_1)/length(beta_1)
beta_2 = c()
for (i in 1:nrow(c)) {
  c_2 = c[i, 2]
  c_3 = c[i, 3]
  p_2 = p[2]
  r_3 = r[3]
  beta_2[i] = (p_2*c_2^(-alpha))/(r_3*c_3^(-alpha))
}
beta_hat_2 = sum(beta_2)/length(beta_2)

# Beta estimates
print(c(beta_hat_1, beta_hat_2))
```

### Question 2
Notice that
$$ J(\beta) = \beta'A\beta \\ = \begin{pmatrix} \beta_1 & \beta_2 \end{pmatrix} \begin{pmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{pmatrix} \begin{pmatrix} \beta_1 \\ \beta_2 \end{pmatrix} \\
= \sum_{i=1}^2\sum_{j=1}^2\beta_i\beta_ja_{ij} \\ = \beta_1^2a_{11} + \beta_2^2a_{22} + \beta_1\beta_2a_{21} + \beta_1\beta_2a_{12} $$
Hence, the partial derivative of $J(\beta)$ w. r. t. $\beta_i$ is
$$ \frac{\partial J(\beta)}{\partial \beta_i} = 2\beta_ia_{ii} + \beta_ja_{ji} + \beta_ja_{ij} $$
We can then write the Jacobian matrix $\frac{\partial J(\beta)}{\partial \beta}$ as a vector of these partial derivatives
$$ \frac{\partial J(\beta)}{\partial \beta} = (A + A')\beta $$
Therefore, $\frac{\partial J(\beta)}{\partial \beta} = 2A\beta$ if and only if A is symmetric, i.e. if and only if $a_{ij}=a_{ji}, \forall i \neq j$.

### Question 3
We know that $\Sigma=Cov(e)=E\left[(e)(e)^{\prime}\right]-E[e] E[e]^{\prime}$, for a random vector $e$. Hence, for some nonstochastic matrix $A \in \mathbb{R}^{k \times n}$, we have
$$ Cov(Ae) = E\left[(A e)(A e)^{\prime}\right]-E[A e] E[A e]^{\prime}\\ =E\left[A e e^{\prime} A^{\prime}\right]-E[A e] E\left[e^{\prime} A^{\prime}\right] \\=A\left(E\left[e e^{\prime}\right]-E[e] E\left[e^{\prime}\right]\right) A^{\prime} \\= A Cov(e) A'= A \Sigma A' .$$

### Question 4
Since $\mathbb{E}[e|z]=0$, by the Law of Iterated Expectations (LIE), we have
$$ \mathbb{E}[z'e]=\mathbb{E}[\mathbb{E}[z'e|z]]=\mathbb{E}[z'\mathbb{E}[e|z]]=0.$$
Also, by the result obtained in the previous item, we have that
$$ Var(z'e) = z'Var(e)z$$
If we call $Var(e)=\Sigma$ we have $Var(z'e)=z' \Sigma z$. Therefore,
$$ (z'e) \sim \mathcal{N}(0, z' \Sigma z). $$

### Question 5
Notice 1st that since $x$ is uniformly distributed, we have
$$ f(x) = \begin{cases} 
\frac{1}{b-a}, & \text{if } x \in [a, b] \\
0, & \text{otherwise }
\end{cases} $$
which implies
$$ f'(x)=0 \land f''(x)=0 $$
We know that, assuming i.i.d. draws, we obtain
$$ Bias[\hat{f}(x_0)]=\mathbb{E}[\hat{f}(x_0)]-f(x_0) \approx \frac{h^2}{2}f''(x_0)\int z^2K(z)dz + O(h^3) $$
Therefore, we have
$$ Bias[\hat{f}(x_0)] \approx 2 \cdot 0 \cdot \int z^2K(z)dz + O(h^3) = O(h^3) 
$$

### Question 6
```{r}
# Loading data
pacman::p_load(
  here
)
iv_data = readRDS(here("problem_sets/data", "iv_data.Rds"))
```
1. The jacobian of $\bar{g}_n(\beta)$ is
$$ G_n(\beta)= \frac{\partial \bar{g_n}(\beta)}{\partial \beta}=-\frac{1}{n}\sum_{i=1}^n z_i x'_i $$
which does not depend on $\beta$.
2. Notice that, with the identity matrix as the weighting matrix, we get
$$ J(\beta)=\bar{g}'_n(\beta)W_n\bar{g}_n(\beta)=\bar{g}'_n(\beta)\bar{g}_n(\beta) $$
Hence, by coding
```{r}
# Seting the variables
y = iv_data[, 1] # Dependent variable
x = as.matrix(iv_data[, 2:3]) # Endogenous variables
z = as.matrix(iv_data[, 4:6]) # Instruments

# Defining the moment function and the objective function
g_n = function(beta){
  u = y - x%*%beta
  g_n_beta = colMeans(sweep(z, 1, u, `*`))
  return(g_n_beta)
}
J_beta = function(beta){
  g_n_beta = g_n(beta)
  return(t(g_n_beta) %*% g_n_beta)
}

# Minimizing the objective function
result = optim(par = c(0, 0), fn = J_beta)

# Printing the result
beta_hat = result$par
objective_value = result$value
```
we obtain
```{r}
cat("Beta estimate:", beta_hat, "\n")
cat("Objective function value:", objective_value, "\n")
```
3. By using $\hat{\beta}$, we obtain
```{r}
# Defining the "g_i" function for each observation i
g_i = function(i, beta){
  u_i = as.numeric(y[i] - x[i, ] %*% beta)
  g_i_beta = z[i, ] * u_i
  return(g_i_beta)
}

# Calculating S_hat 
S_hat = matrix(0, ncol = 3, nrow = 3)
n = nrow(iv_data) # Nº of observations
for (i in 1:n) {
  g_i_beta_hat = g_i(i, beta_hat)
  S_hat = S_hat + g_i_beta_hat %*% t(g_i_beta_hat)
}
S_hat = S_hat/n
cat("S_hat:\n")
S_hat
```
4. By repeiting step 2
```{r}
# Redefining the objective function using S_hat
S_hat_inv = solve(S_hat)
J_beta_opt = function(beta){
  g_n_beta = g_n(beta)
  return(t(g_n_beta) %*% S_hat_inv %*% g_n_beta)
}

# Minimizing the objective function
result_opt = optim(par = c(0, 0), fn = J_beta_opt)

# Printing the result
beta_hat_opt = result_opt$par
```
we obtain
```{r}
cat("Beta estimate:", beta_hat_opt, "\n")
```
5. Encoding
```{r}
# Defining the Jacobian G_n(β)
G_n = function(beta) {
  n = nrow(iv_data)         # Nº of observations
  g_n_beta = g_n(beta)      # Calculating g_n(β)
  
  # Initialize the Jacobian matrix G_n(β)
  G_n_matrix = matrix(0, nrow = 3, ncol = 2)

  # Calculating the Jacobian
  for (i in 1:n) {
    u_i = y[i] - x[i, ] %*% beta  
    for (j in 1:2) {
      # Partial derivatives of g_n(β) with respect to β_j
      G_n_matrix[, j] = G_n_matrix[, j] + z[i, ] * (-x[i, j]) * (1/n)
    }
  }
  
  return(G_n_matrix)
}

# Calculate the Jacobian in beta_hat
G_hat = G_n(beta_hat)

# Result
cat("Jacobian G_hat:\n")
G_hat
```
6. Finally
```{r}
# Calculating the product G_hat' S_hat^{-1} G_hat
G_hat_transpose = t(G_hat)
product = G_hat_transpose %*% S_hat_inv %*% G_hat

# Calculating the covariance matrix V_GMM
V_GMM = (1/n) * solve(product)

# Resultado
cat("Estimated covariance matrix V_GMM:\n")
V_GMM
```

### Question 7
Encoding
```{r}
# Loading needed packages
pacman::p_load(
  tidyverse,
  fixest
)

# Importing the database
temperature_states = readRDS(here("problem_sets/data", "temperature_states.Rds"))

# Step 1: Calculate the national average daily maximum temperature
national_avg_temp = temperature_states %>%
  group_by(date) %>% # Group by date
  # Calculate the average max temperature
  summarise(avg_temp = mean(mean_tmax, na.rm = TRUE))

# Step 2: Count the number of days with average temperature above 32°C per year-month
days_above_32C = national_avg_temp %>%
  mutate(year_month = format(date, "%Y-%m")) %>% # Create a year-month column
  # Filter for temperatures above 32°C
  filter(avg_temp > 32) %>%
  group_by(year_month) %>% # Group by year-month
  summarise(days_above_32C = n()) %>% # Count the days
  # Add columns for the year and month
  mutate(year = as.numeric(substring(year_month, 1, 4)),
         month = as.numeric(substring(year_month, 6, 7)))

# Step 3: Regression of the count of days above 32°C on calendar year with month fixed effects
# Perform regression using fixest
model = feols(days_above_32C ~ year | month, data = days_above_32C)

# Display regression results
summary(model)

# Step 4: Repeat the analysis for each region
results_by_region = lapply(unique(temperature_states$region), function(reg) {
  # Filter the data for the specific region
  region_data = temperature_states %>%
    filter(region == reg)  # Keep only the rows for the current region
  
  # Calculate the average daily temperature for the region
  region_avg_temp = region_data %>%
    group_by(date) %>%  # Group by date
    # Calculate average max temperature for the region
    summarise(avg_temp = mean(mean_tmax, na.rm = TRUE)) 
  
  # Count the number of days with average temperature above 32°C per year-month for the region
  region_days_above_32C = region_avg_temp %>%
    mutate(year_month = format(date, "%Y-%m")) %>% # Create a year-month column
    filter(avg_temp > 32) %>% # Filter for temperatures above 32°C
    group_by(year_month) %>% # Group by year-month
    summarise(days_above_32C = n()) %>% # Count the days
    # Add columns for the year and month
    mutate(year = as.numeric(substring(year_month, 1, 4)),
           month = as.numeric(substring(year_month, 6, 7)))
  
  # Perform regression for the region
  model_region = feols(days_above_32C ~ year | month,
                       data = region_days_above_32C)
  
  # Return the region name and model
  return(list(region = reg, model = model_region))
})

# Display results by region
results_by_region
```

### Question 8
Data from 2001-2004
```{r}
pacman::p_load(
  tidyverse,
  fixest
)

temperature_states = readRDS(here("problem_sets/data", "temperature_states.Rds"))

# Filter for the years 2001-2004
filtered_data <- temperature_states %>%
  filter(year >= 2001 & year <= 2004)

# Calculate average maximum temperature (tmax) per month and state
monthly_avg_tmax <- filtered_data %>%
  group_by(state, month) %>%
  summarise(avg_temp = mean(mean_tmax, na.rm = TRUE)) %>%
  ungroup()

# Calculate kernel density estimation
kde <- density(monthly_avg_tmax$avg_temp, bw = 2)

# Plot
kde_df <- data.frame(x = kde$x, y = kde$y)
ggplot(kde_df, aes(x = x, y = y)) +
  geom_line(color = "blue") +
  labs(title = "Kernel Density Estimation of Average Monthly Tmax (2001-2004)",
       x = "Average Monthly Tmax",
       y = "Density") +
  theme_minimal()

```

Data from 2018-2021
```{r}
pacman::p_load(
  tidyverse,
  fixest
)

temperature_states = readRDS(here("problem_sets/data", "temperature_states.Rds"))

# Filter for the years 2018-2021
filtered_data <- temperature_states %>%
  filter(year >= 2018 & year <= 2021)

# Calculate average maximum temperature (tmax) per month and state
monthly_avg_tmax <- filtered_data %>%
  group_by(state, month) %>%
  summarise(avg_temp = mean(mean_tmax, na.rm = TRUE)) %>%
  ungroup()

# Calculate kernel density estimation
kde <- density(monthly_avg_tmax$avg_temp, bw = 2)

# Plot
kde_df <- data.frame(x = kde$x, y = kde$y)
ggplot(kde_df, aes(x = x, y = y)) +
  geom_line(color = "green") +
  labs(title = "Kernel Density Estimation of Average Monthly Tmax (2018-2021)",
       x = "Average Monthly Tmax",
       y = "Density") +
  theme_minimal()
```

### Question 9
Encoding
```{r}
# Loading needed package
pacman::p_load(
  np
)
# Step 1: Calculate the average maximum temperature per month and per state, as done previously
avg_temp_per_month_region = temperature_states %>%
  group_by(state, year_month, region, year) %>%
  summarise(avg_temp = mean(mean_tmax, na.rm = TRUE)) %>%
  mutate(year = as.numeric(substring(year_month, 1, 4)),
         month = as.numeric(substring(year_month, 6, 7)))

# Step 2: Define a function to perform local constant regression for each region
local_constant_regression = function(region_data, kernel = "gaussian", bandwidth = 2) {
  # Extract year and temperature data
  x = region_data$year # Calendar year
  y = region_data$avg_temp # Average temperature
  
  # Perform local constant regression using npreg() from the np package
  np_model = npreg(tydat = y, txdat = x, regtype = "lc", bwmethod = "cv.aic", ckertype = kernel, bws = bandwidth)
  
  # Create a dataframe to hold the fitted values (estimates) for plotting
  fitted_data = data.frame(
    year = np_model$eval$x,
    fitted_temp = np_model$mean,
    region = region_data$region
  )
  
  return(fitted_data)
}

# Step 3: Apply the regression to each of the 5 macro regions
regions = unique(temperature_states$region) # Extract unique macro regions
fitted_results = list() # List to store results for each region

for (reg in regions) {
  region_data = avg_temp_per_month_region %>%
    filter(region == reg) # Filter data for the current region
  
  # Perform local constant regression and store the fitted results
  fitted_results[[reg]] = local_constant_regression(region_data)
}

# Step 4: Plot the results for all regions
plot_data = do.call(rbind, fitted_results) %>% 
  mutate(region = ifelse(region == 1, "North",
                         ifelse(region == 2, "Northeast",
                                ifelse(region == 3, "Southeast",
                                       ifelse(region == 4, "South",
                                              "Central West")))))

ggplot(plot_data, aes(x = year, y = fitted_temp, color = region)) +
  geom_line(linewidth = 1.2) +
  labs(title = "Local Constant Regression of Average Temperature by Year",
       x = "Year",
       y = "Fitted Average Monthly Temperature (°C)",
       color = "Region") +
  theme_minimal() +
  scale_color_manual(values = c("North" = "blue", "Northeast" = "green", 
                                "Southeast" = "red", "South" = "purple", 
                                "Central West" = "orange"))
```

### Rendering
```{r}
rmarkdown::render("ps1.Rmd",
                  output_format = "html_document",
                  output_dir = here("problem_sets/outputs"))
```

